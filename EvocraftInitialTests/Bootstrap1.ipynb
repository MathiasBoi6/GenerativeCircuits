{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Mine\\Master\\MyNca\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "\n",
    "from minecraft_pb2 import *\n",
    "import minecraft_pb2_grpc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import diffusers\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from diffusers import UNet2DModel, DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel('localhost:5001')\n",
    "client = minecraft_pb2_grpc.MinecraftServiceStub(channel)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockList = [\n",
    "    REDSTONE_TORCH, REDSTONE_WIRE, UNPOWERED_REPEATER, UNPOWERED_COMPARATOR, PISTON, COBBLESTONE, AIR, STICKY_PISTON, SLIME,\n",
    "]\n",
    "\n",
    "orientationList = [\n",
    "    NORTH, WEST, SOUTH, EAST, UP, DOWN\n",
    "]\n",
    "\n",
    "channels = len(blockList) + len(orientationList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model\n",
    "\n",
    "imageSize = 32\n",
    "\n",
    "timesteps = 200 \n",
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=timesteps,\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    beta_schedule=\"squaredcos_cap_v2\", \n",
    ")\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=imageSize,\n",
    "    in_channels=channels, # random image, conditioning\n",
    "    out_channels=channels, # Block, orientation\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(64, 128, 256, 512),\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Temp remove cell\n",
    "\n",
    "offset = {'x': 10, 'y': 4, 'z': 5}\n",
    "client.fillCube(FillCubeRequest(\n",
    "    cube=Cube(\n",
    "        min=Point(x=offset['x'], y=offset['y'], z=offset['z']),\n",
    "        max=Point(x=offset['x'] + imageSize, y=offset['y'], z=offset['z'] + imageSize)\n",
    "    ),\n",
    "    type=AIR\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InferNTimes(n):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Start from pure noise.\n",
    "        x = torch.randn((n, channels, imageSize, imageSize)).to(device)\n",
    "\n",
    "        for t in scheduler.timesteps:\n",
    "            t_tensor = torch.tensor([t], device=device).long()\n",
    "            modelOutput = model(x, t_tensor)\n",
    "            predNoise = modelOutput.sample\n",
    "\n",
    "            stepOut = scheduler.step(predNoise, t, x)\n",
    "            x = stepOut.prev_sample\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer model\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Start from pure noise.\n",
    "    x = torch.randn((1, channels, imageSize, imageSize)).to(device)\n",
    "\n",
    "    for t in scheduler.timesteps:\n",
    "        t_tensor = torch.tensor([t], device=device).long()\n",
    "        modelOutput = model(x, t_tensor)\n",
    "        predNoise = modelOutput.sample\n",
    "\n",
    "        stepOut = scheduler.step(predNoise, t, x)\n",
    "        x = stepOut.prev_sample\n",
    "\n",
    "    sampledImage = x.cpu()\n",
    "\n",
    "sampledImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TensorToBlocks(input, offset):\n",
    "    blockChannels = input[:, :-len(orientationList), :, :]\n",
    "    orientationChannels = input[:, -len(orientationList):, :, :]\n",
    "    \n",
    "    blockIds = blockChannels.argmax(dim=1).squeeze()\n",
    "    dirs = orientationChannels.argmax(dim=1).squeeze()\n",
    "\n",
    "    blocks = []\n",
    "    for i in range(blockIds.shape[0]):\n",
    "        for j in range(blockIds.shape[1]):\n",
    "            blocks.append(\n",
    "                Block(\n",
    "                    position=Point(x=i + offset['x'], y=offset['y'], z=j + offset['z']), \n",
    "                    type=blockList[blockIds[i, j]], \n",
    "                    orientation=orientationList[dirs[i, j]]))\n",
    "    return Blocks(blocks=blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outblocks = TensorToBlocks(sampledImage, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.spawnBlocks(outblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nModels = InferNTimes(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TensorsToBlocks(tensors, offset, stride):\n",
    "    BlocksList = []\n",
    "    rows = int(math.sqrt(len(tensors)))\n",
    "    for i in range(len(tensors)):\n",
    "        buildOffset = offset.copy()\n",
    "        buildOffset['y'] = 4\n",
    "        buildOffset['x'] = buildOffset['x'] + i % rows * (stride + imageSize)\n",
    "        buildOffset['z'] = buildOffset['z'] + int(i / rows) * (stride + imageSize)\n",
    "        BlocksList.append(TensorToBlocks(tensors[i:i+1], buildOffset))\n",
    "    return BlocksList # could collect all blocks within a single Blocks(), which would mean the blocks can all be communicated to the server in a single message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nMcModels = TensorsToBlocks(nModels, offset, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mcModel in nMcModels:\n",
    "    client.spawnBlocks(mcModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temp remove cell\n",
    "rows = int(math.sqrt(len(nMcModels)))\n",
    "stride = 5\n",
    "for i in range(len(nMcModels)):\n",
    "    buildOffset = offset.copy()\n",
    "    buildOffset['y'] = 4\n",
    "    buildOffset['x'] = buildOffset['x'] + i % rows * (stride + imageSize)\n",
    "    buildOffset['z'] = buildOffset['z'] + int(i / rows) * (stride + imageSize)\n",
    "\n",
    "    client.fillCube(FillCubeRequest(\n",
    "        cube=Cube(\n",
    "            min=Point(x=buildOffset['x'], y=buildOffset['y'], z=buildOffset['z']),\n",
    "            max=Point(x=buildOffset['x'] + imageSize, y=buildOffset['y'], z=buildOffset['z'] + imageSize)\n",
    "        ),\n",
    "        type=AIR\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative log of cosine similarity between predicted noise and actual noise\n",
    "def replusionLoss(predNoise, noise):\n",
    "    cosSim = F.cosine_similarity(predNoise, noise, dim=-1)\n",
    "    return -torch.log(1 - cosSim + 1e-6).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSampleDataset(Dataset):\n",
    "    def __init__(self, negativeSamples):\n",
    "        self.negativeSamples = negativeSamples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.negativeSamples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.negativeSamples[idx]\n",
    "\n",
    "#dataset = NegativeSampleDataset(negativeSamples)\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 4\n",
    "dataset = NegativeSampleDataset(nModels)\n",
    "dataloader = DataLoader(dataset, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 15, 32, 32])\n",
      "torch.Size([4, 15, 32, 32])\n",
      "torch.Size([1, 15, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch.shape)\n",
    "    # How many batches does this get?\n",
    "    # does this make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = -0.640103\n",
      "Epoch 10: Loss = -0.576219\n",
      "Epoch 20: Loss = -0.629864\n",
      "Epoch 30: Loss = -0.592610\n",
      "Epoch 40: Loss = -0.484804\n",
      "Epoch 50: Loss = -0.543534\n",
      "Epoch 60: Loss = -0.249322\n",
      "Epoch 70: Loss = -0.631184\n",
      "Epoch 80: Loss = -0.659864\n",
      "Epoch 90: Loss = -0.249465\n",
      "Epoch 100: Loss = -0.493726\n"
     ]
    }
   ],
   "source": [
    "# Negative Training\n",
    "epochs = 101\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(0, timesteps, (batch.shape[0],), device=device).long()\n",
    "\n",
    "        # Sample random noise.\n",
    "        noise = torch.randn_like(batch)\n",
    "        noisy_image = scheduler.add_noise(batch, noise, t)\n",
    "\n",
    "        # Predict the noise using the model.\n",
    "        model_output = model(noisy_image, t)\n",
    "        pred_noise = model_output.sample\n",
    "\n",
    "        # Compute the loss \n",
    "        loss = replusionLoss(pred_noise, noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
